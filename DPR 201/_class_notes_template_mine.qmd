---
title: "DPR 201 Class Notes"
format: html
---

Here's a Quarto file for you to take class notes. It includes headers that correspond to different subjects we'll cover. This is a great place to try out example code in the lecture notes and to follow along with code-alongs in class.

## Looking at Data

```{r}
library(tidyverse)

usaidhr <- read_csv(
  "https://tinyurl.com/usaidhr"
)
```


```{r}
glimpse(usaidhr)
```


### scatter plots

```{r}
ggplot(usaidhr) +
  aes(x = physint, y = aid) +
  # geom_point() +
  geom_smooth(
    method = "lm",
    se = F
  ) +
  labs(
    title = "Here's a title",
    subtitle = "A subtitle",
    x = "Physical Integrity",
    y = "U.S. Aid",
    caption = "Data for 1945-2023"
  )
```

```{r}
usaidhr |>
  filter(
    aid == max(aid)
  )
```

### Line plot

```{r}
ggplot(usaidhr) +
  aes(x = year, aid) +
  geom_smooth()
```

```{r}
ggplot(usaidhr) +
  aes(x = year, y = aid) +
  stat_summary(
    geom = "line",
    fun = sum
  )
```

### column plot

```{r}
ggplot(usaidhr) +
  aes(x = aid, y = reorder(leader, -year)) +
  geom_col()
```


## Modeling Data with Linear Regression


## Quantifying the Role of Chance


## From Relationships to Predictions

```{r}
library(tidyverse)
dt <- read_csv(
  "https://tinyurl.com/pres-forecast"
)
```


### Make a predictive model

```{r}
fit <- lm(
  inc_vote_margin ~ inc_net_approval +
    inc_running,
  data = dt
)
summary(fit)
```

```{r}
newdt <- tibble(
  inc_net_approval = 3,
  inc_running = c(1, 0)
)
predict(fit, newdata = newdt)
newdt |>
  mutate(
    prediction = predict(fit, newdt)
  ) -> newdt
```



### Generate a forecast with uncertianty

```{r}
library(simqi)

predict(
  fit,
  newdata = newdt,
  se.fit = T
)
```


```{r}
fit |>
  sim_qi(
    newdata = newdt,
    return_newdata = T,
    nsim = 10000
  ) |>
  group_by(inc_net_approval, inc_running) |>
  summarize(
    mean = mean(y),
    lower = quantile(y, 0.025),
    upper = quantile(y, 0.975)
  )
```

```{r}
newdt <- expand_grid(
  inc_net_approval = unique(dt$inc_net_approval),
  inc_running = 0:1
)
fit |>
  sim_qi(
    newdata = newdt,
    return_newdata = T,
    vcov = sandwich::vcovHC(fit, type = "HC1")
  ) |>
  group_by(inc_net_approval, inc_running) |>
  summarize(
    mean = mean(y),
    lower = quantile(y, 0.025),
    upper = quantile(y, 0.975)
  ) -> pred_dt
```

```{r}
ggplot(pred_dt) +
  aes(inc_net_approval, mean) +
  geom_line() +
  geom_ribbon(
    aes(ymin = lower, ymax = upper),
    alpha = 0.3
  ) +
  facet_wrap(~ inc_running)
```



## Picking the Best Forecast


Install if you need it:

install.packages("modelr")


```{r}
## packages we need
library(tidyverse)
library(modelr)
library(simqi)

## read in the data
presdt <- read_csv(
  "https://tinyurl.com/pres-forecast"
)
```


List of model specifications to try:

```{r}
forms <- list(
  inc_vote_margin ~ gdp_pct_change + inc_net_approval,
  inc_vote_margin ~ inflation_pct_change + inc_net_approval,
  inc_vote_margin ~ third_party_present,
  inc_vote_margin ~ inc_running,
  inc_vote_margin ~ gdp_pct_change + inflation_pct_change
)
```


Generate LOO cross-validation sets with the data:

```{r}
cvdt <- crossv_loo(presdt)
```

Bring in each model specification to try:

```{r}
cvdt <- expand_grid(
  forms = forms,
  cvdt
)
```


Use `map2()` to fit models to each training set:

```{r}
cvdt <- cvdt |>
  mutate(
    fits = map2(
      .x = forms,
      .y = train,
      .f = ~ lm(.x, data = .y)
    )
  )
```

Use `map2()` and `rmse()` to get the RMSE of each model fit based on the left-out observation:

```{r}
cvdt <- cvdt |>
  mutate(
    rmse = map2(
      .x = fits,
      .y = test,
      .f = ~ rmse(model = .x, data = .y)
    )
  )

cvdt <- cvdt |>
  unnest(rmse)
```

Add a model label column and visualize:

```{r}
cvdt <- cvdt |>
  mutate(
    model = rep(
      c(
        "PEM",
        "PEM-inf",
        "3rd Party",
        "Incumbent",
        "Economy"
      ),
      each = 19
    )
  )
```

```{r}
ggplot(cvdt) +
  aes(model, rmse) +
  geom_boxplot() +
  labs(
    title = "RMSE for different presidential election models",
    x = NULL,
    y = "RMSE"
  )
```


```{r}
ggplot(cvdt) +
  aes(.id, rmse, color = model) +
  geom_point() +
  geom_smooth(
    method = "lm",
    se = F,
    formula = y ~ 1
  )
```

Generate predictions for the economy model:

```{r}
## estimate the economy model:
fit <- lm(
  inc_vote_margin ~ gdp_pct_change +
    inflation_pct_change,
  data = presdt
)

## generate predictions
preds <- sim_qi(
  mod = fit,
  newdata = tibble(
    gdp_pct_change = 2.8,
    inflation_pct_change = 2.9
  )
)

## visualize
ggplot(preds) +
  aes(y) +
  geom_histogram() +
  geom_vline(
    xintercept = mean(preds$y),
    color = "red"
  ) +
  geom_vline(
    xintercept = 0
  )
```



## From Relationships to Causation

```{r}
library(tidyverse)
tibble(
  # values without treatment
  Y0 = rnorm(100),
  
  # values with treatment
  Y1 = 1/2 + Y0,
  
  # treatment assignment
  D = rep(0:1, each = 50) |>
    sample(),
  
  # reveal outcomes
  Yobs = Y1 * D + Y0 * (1 - D)
) -> Data
```

Estimate the true ATE:

```{r}
mean(Data$Y1 - Data$Y0)
```


What we can actually estimate in the real world:

```{r}
mean(Data$Yobs[Data$D == 1]) - mean(Data$Yobs[Data$D == 0])
```

Equivalently using a linear model:

```{r}
lm(Yobs ~ D, Data) |> coef()
```

What about uncertainty and hypothesis testing? Introducing the sharp null:

d = Y1 - Y0 = 0

To test, randomly reassign treatment. If the null is true, this gives you the distribution of possible ATE estimates you'd expect to get.

```{r}
map_dfr(
  .x = 1:200,
  .f = 
    ~ coef(lm(Yobs ~ D, data = Data |> mutate(D = sample(D))))[2]
) -> null_output

ggplot(null_output) +
  aes(x = D) +
  geom_histogram() +
  geom_vline(
    xintercept = coef(lm(Yobs ~ D, Data))[2],
    color = "red"
  )
```




```{r}
map_dfr(
  .x = 1:200,
  .f = ~ coef(
    lm(Yobs ~ D, Data |> 
         mutate(
           D = sample(D),
           Yobs = Y1 * D + Y0 * (1 - D)
         ))
  )[2]
) -> ate_output

ggplot(ate_output) +
  aes(D) +
  geom_histogram() +
  geom_vline(xintercept = .5, color = "red")
```


## Randomized Trials

```{r}
library(tidyverse)
url <- "https://raw.githubusercontent.com/milesdwilliams15/Teaching/main/DPR%20201/Data/aidExperiment.csv"
Data <- read_csv(url)
view(Data)
```


### Simple Randomization

```{r}
library(randomizr)

Data |>
  mutate(
    simpleTr = simple_ra(N = n())
  ) -> Data

Data |>
  count(simpleTr)
```

### Complete Randomization

```{r}
Data |>
  mutate(
    completeTr = complete_ra(N = n(), m = 200)
  ) -> Data

Data |>
  count(completeTr)
```


### Block randomization

```{r}
Data |>
  mutate(
    blockTr = block_ra(
      blocks = gender
    )
  ) -> Data

Data |>
  group_by(gender) |>
  count(simpleTr)

Data |>
  group_by(gender) |>
  summarize(
    aid = mean(aid, na.rm = T)
  )
```

```{r}
Data |>
  mutate(
    blockTr = block_ra(
      blocks = paste(gender, educ)
    )
  ) -> Data

Data |>
  group_by(gender, educ) |>
  count(blockTr)
```


### Cluster randomization

```{r}
Data |>
  mutate(
    clusterTr = cluster_ra(
      clusters = paste(gender, educ)
    )
  ) -> Data

Data |>
  group_by(gender, educ) |>
  count(clusterTr)
```

### Analyze how you randomize

```{r}
## simple or complete ra:
lm(aid ~ completeTr, data = Data)
```


```{r}
library(estimatr)
lm_robust(aid ~ completeTr, data = Data, se_type = "HC1")
```

HC2 is randomization justified. HC1 is not.

```{r}
lm_robust(aid ~ completeTr, data = Data, se_type = "HC2")
```

```{r}
## block randomization:

# way 1
lm_robust(
  aid ~ blockTr + paste0(gender, educ),
  data = Data,
  se_type = "HC2"
)

# way 2
lm_robust(
  aid ~ blockTr,
  fixed_effects = ~ paste0(gender, educ),
  data = Data,
  se_type = "HC2"
)

# Way 3 (Lin Estimator)
lm_lin(
  aid ~ blockTr,
  covariates = ~ paste(gender, educ),
  data = Data,
  se_type = "HC2"
)
```

```{r}
lm_robust(
  aid ~ clusterTr,
  data = Data,
  se_type = "HC2"
  #clusters = paste0(gender, educ)
)
```


## Selection on Observables


## Regression Discontinuity

```{r}
library(tidyverse)
library(estimatr)
library(modelsummary)
library(rddtools) # install.packages("rddtools")
data(house) # attaches the house data
```


Add the treatment column:

```{r}
house |>
  mutate(
    tr = ifelse(x > 0, 1, 0)
  ) -> house
```


Estimate the model:

```{r}
lm_robust(
  y ~ tr + x + tr:x,
  data = house,
  se_type = "HC1"
) -> rd_fit

summary(rd_fit)
```

Compare to diff-in-means and plot:

```{r}
lm_robust(
  y ~ tr,
  data = house,
  se_type = "HC1"
) -> md_fit

modelplot(
  list(
    "RD" = rd_fit,
    "Mean-Diff" = md_fit
  ),
  coef_map = c("tr" = "Incumbent")
) +
  geom_vline(
    xintercept = 0,
    linetype = 2
  )
```

Making an RD plot:

```{r}
## open {simqi}
library(simqi)

## {simqi} doesn't play well with lm_robust objects
## so we have to re-estimate the model using lm()
lm(
  y ~ tr * x,
  data = house
) -> lm_fit

## simulate predictions
lm_fit |>
  sim_qi(
    vcov = vcovHC(lm_fit, type = "HC1"),
    newdata = tibble(
      x = c(seq(-.5, .5, by = 0.1), 0.001),
      tr = ifelse(x > 0, 1, 0)
    ),
    return_newdata = T
  ) -> sim_data

## summarize and visualize the results
sim_data |>
  group_by(x, tr) |>
  summarize(
    pred = mean(y),
    lo = quantile(y, 0.025),
    hi = quantile(y, 0.975)
  ) |>
  mutate(
    tr = ifelse(tr == 1, "Yes", "No")
  ) |>
  ggplot() +
  aes(
    x = x, 
    y = pred, 
    color = tr,
    fill = tr
  ) +
  geom_line() +
  geom_ribbon(
    aes(ymin = lo, ymax = hi),
    alpha = 0.3
  ) +
  geom_vline(
    xintercept = 0,
    linetype = 2
  ) +
  labs(
    title = "Regression discontinuity in action",
    subtitle = "Effect of incumbency on election outcomes",
    x = "Previous Election Margin",
    y = "Current Vote Share",
    color = "Incumbent?",
    fill = "Incumbent?"
  ) +
  scale_x_continuous(
    labels = scales::percent
  ) + 
  scale_y_continuous(
    labels = scales::percent
  ) +
  theme(
    legend.position = "bottom"
  ) +
  annotate(
    "text",
    x = 0,
    y = 0.5,
    label = "''%<-%'The LATE'",
    parse = T,
    hjust = 0
  )
```


Picking a bandwidth:

```{r}
bandwidth <- seq(0.05, 1, by = 0.05)
bandwidth |>
  map(
    ~ lm(
      y ~ tr * x,
      data = house |>
        filter(abs(x) < .x)
    )
  ) -> fits

names(fits) <- bandwidth

modelplot(
  fits,
  coef_map = c("tr" = "Incumbent")
) +
  geom_vline(
    xintercept = 0,
    linetype = 2
  )
```




## Difference-in-Differences


Set up and read in the data:

```{r}
## packages
library(tidyverse)
library(estimatr)
library(modelsummary)

## Card and Krueger (1992) data
ck <- read_csv(
  "https://raw.githubusercontent.com/milesdwilliams15/Teaching/refs/heads/main/DPR%20201/Data/card_krueger_92.csv"
)
```

Estimate the D-in-D:

```{r}
dd_fit <- lm_robust(
  ft_employment ~ min_wage_change,
  fixed_effects = ~ unit + period,
  data = ck,
  se_type = "stata",
  clusters = unit
)
```

Visualize the results:

```{r}
modelplot(
  dd_fit
) +
  geom_vline(xintercept = 0)
```

Estimate the overall average difference:

```{r}
avg_fit <- lm_robust(
  ft_employment ~ min_wage_change,
  data = ck,
  se_type = "stata",
  clusters = unit
)
```

Estimate the difference using SOO:

```{r}
soo_fit <- lm_robust(
  ft_employment ~ min_wage_change + wave1_st_wage + 
    franchise_name + co_owned + region,
  data = ck,
  se_type = "stata",
  clusters = unit
)
```

Estimate the difference using RD:

```{r}
rd_fit <- lm_robust(
  ft_employment ~ min_wage_change,
  data = ck |> filter(state == "NJ"),
  se_type = "stata",
  clusters = unit
)
```

Put everything in a single visualization and compare:

```{r}
modelplot(
  list(
    "D-in-D" = dd_fit,
    "Avg. Diff" = avg_fit,
    "SOO" = soo_fit,
    "RD" = rd_fit
  ),
  coef_map = c("min_wage_change" = "")
) +
  geom_vline(xintercept = 0)
```

Read in congress data for a TWFE example:

```{r}
congress_dt <- read_csv(
  "https://raw.githubusercontent.com/milesdwilliams15/Teaching/main/DPR%20201/Data/CongressionalData.csv"
)
```

```{r}
dd_fit <- lm_robust(
  cvp ~ republican,
  fixed_effects = state_dist + cong,
  data = congress_dt,
  se_type = "stata",
  clusters = state_dist
)
```

```{r}
modelplot(dd_fit)
```


```{r}
dres <- lm(
  republican ~ state_dist + as.factor(cong),
  data = congress_dt
) |> resid()
```

Calculate share with negative weights:

```{r}
congress_dt |>
  summarize(
    mean(dres > 0 & republican == 1),
    mean(dres < 0 & republican == 0)
  )
```

