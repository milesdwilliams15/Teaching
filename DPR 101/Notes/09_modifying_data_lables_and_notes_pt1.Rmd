---
title: "Modifying data with `{dplyr}`"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,
                      message = F,
                      warning = F,
                      dpi = 500,
                      out.width = "75%")
```

## Learning Objectives

- Apply the main `{dplyr}` functions to manipulate a dataset
- Layer complexity by chaining together multiple `{dplyr}` functions to solve a problem.


## Using `{dplyr}` for data manipulation/wrangling

The `{dplyr}` package is a powerful tool for letting us transform a dataframe into what we need for analysis and data visualization. This package is part of the `{tidyverse}` and is automatically opened when you use `library(tidyverse)`.

There are 6 key `{dplyr}` functions that you need to know about:

- `filter()`: Choose observations based on their values (==, !=, >, <, >=, <=)
- `arrange()`: Reorder the rows (sort based on a variable)
- `select()`: Choose variables (columns) based on their names
- `mutate()`: Use existing variables to create new variables
- `summarize()`: Collapse many variables into a single summary 
- `group_by()`: Specify the scope of the function that you want to perform (for example, calculate the average votes cast for a candidate by education level). ORDERING MATTERS!

We'll start by opening the tidyverse as always:

```{r, warning=FALSE, message=FALSE}
library(tidyverse)
```


While the functions available with `{dplyr}` are functions, sometimes we call them “verbs”, and they all take input in a similar structure.

`filter(data, colname == "value" & colname >= 1000)`

We can chain together multiple dplyr “layers”, like with ggplot, but we use the `%>%` pipe instead of `+`.

1. First, we start with the data frame
2. Then, we add arguments that describe what to do with the data frame, using the column (variable) names. Note that we don’t need to put the column names in quotes, because we’ve already specified the data frame that they are contained in, R will be able to find them as a “known” object. 
3. The output is a new data frame

Do you recall using `filter()` for your last data challenge? What do we need to add if we want to save the output so we can do things with it later? Any time we filter data, if we want to save it we need to make sure we assign the output a name so that it is a known object in R's memory.

```
filtered_data <- data %>%
	filter(column_name == "some text")
```

To filter, we need to remember and know how to use the comparison operators: 

- Greater than `>`
- Less than `<`
- Greater than or equal to `>=`
- Less than or equal to `<=`
- Equal to `==`
- Not equal to `!=`
- In `%in%`
- Is NA? `is.na()`

Aside: Recall some common mathematical operators (should follow order of operations).

- addition `+`
- subtraction `-`
- multiplication `*`
- division `/`
- square `^2` 

We also need to know the logical operators

- and `&`
- or `|`
- not `!`


Let’s try using filter with some data from the `{peacesciencer}` package.

You may need to install the package first:
```
install.packages("peacesciencer")
```

Then you can open it:
```{r}
library(peacesciencer)
```

This package has a lot of useful data for studying conflict, which is a core subject of study in the political science field called international relations or IR.

We can call the data we want and customize it using a variety of functions (and we can do this all using the `%>%` operator from `{dplyr}`!).

```{r}
create_stateyears() %>%
  add_cow_majors() %>%
  add_cow_wars(type = "intra") %>%
  add_democracy() %>%
  add_sdp_gdp() -> Data
```

In the above, we made a dataset where the unit of observation is a country-year and for each observation we have information about:

1. Whether the country is classified as a "major power."
2. Whether the country experienced a intra-state war or civil war.
3. Information about the quality of democracy.
4. Information about economic wellbeing.

We can use the `dim()` function to check out the size of the data.

```{r, message=FALSE, warning=FALSE}
dim(Data)
```

With this data, we'll walk through the different `{dplyr}` "verbs" for manipulating data.

### filter()

Let’s just practice filter first, which we’ve already seen in action. Let’s say we only want data for major powers.

```{r}
Data %>%
  filter(cowmaj == 1)
```

OK but what if we want to filter on two variables, major powers that are experiencing civil wars?

```{r}
Data %>%
  filter(cowmaj == 1 & cowintraongoing == 1)
```

OK but what if we want to filter on two variables but make it either or?

```{r}
Data %>%
  filter(cowmaj == 1 | cowintraongoing == 1)
```

What does this give us? Rows are either major powers or countries experiencing civil war.

Note: `filter()` only includes rows where the condition is `TRUE`. So if we want to keep in NA (missing) values, then we need to ask for them explicitly, for example:

What would we do if we wanted only rows where values in a column were blank (indicated by NA on the computer). Would this work?

```
Data %>%
  filter(warnum == NA)
```

Nope! Since NA is a special value that indicates missing data, it cannot be equal to anything, or not equal to anything. This means we can only include or exclude NA using functions designed to do that. For example, is.na() or na.rm=TRUE. The example below would work/

```{r}
Data %>%
  filter(is.na(warnum))
```


### arrange()

We haven’t seen this yet, but it works similarly to `filter()`, except instead of selecting rows, it changes their order - Kind of like using "sort" in Excel, except you know that you won’t accidentally sort just the one row and scramble all your data. 

Let’s sort the dataset by year:

```{r}
Data %>%
  arrange(year)
```

OK, cool, but what if we want to see most recent years first? We can specify the order, and change the default:

```{r}
Data %>%
  arrange(desc(year))
```

But what if we really want to use the warname category? Do you think we can sort on a factor or character? Let’s try! We can try anything in R...

```{r}
Data %>%
  arrange(warname)
```

Awesome. Where do you think the NAs went? How would we check? 
Hint: NAs are always sorted to the end, whether you use ascending or descending order.

### select()

Here’s another one. `select()` is another way to “slice” our dataframe. Usually, we don’t need ALL the variables for a given data analysis, so it is more efficient to just look at the ones that we need. 

How many columns does the data have? Use `ncol()`

```{r}
ncol(Data)
```

Let's just get the ones we want.

```{r}
Data %>%
  select(statenme, year, cowintraongoing, sideadeaths, sidebdeaths)
```

What if we wanted most of the columns, but just not surplus domestic product? Do we have to name all the other columsn? Thankfully, no!

```{r}
Data %>%
  select(-sdpest)
```

We can even use some “helper functions” inside of select() to get even more specific. A few examples are:

- `starts_with("")` 
- `end_with("")`
- `contains("ijk")`

For example, we have a couple columns that contain "war". We can only select those by writing:

```{r}
Data %>%
  select(contains("war"))
```


### mutate()

Sometimes we need to create new variables. This might be a function of an existing column. We tried this, too, recently.

This is our fourth `{dplyr}` command - let’s start chaining some of these together to see how they work! Here’s one that we did before, to select just 5 columns:

```
Data %>%
  select(statenme, year, cowintraongoing, sideadeaths, sidebdeaths)
```

To chain on another command, we use the pipe `%>%`, just like in ggplot where we added layers to our graphic using `+`. Let's make our own calculation of total war deaths.

```{r}
Data %>%
  select(statenme, year, cowintraongoing, 
         sideadeaths, sidebdeaths) %>%
  mutate(
    total_deaths = sideadeaths + sidebdeaths
  )
```


Here's one showing how you can build on new columns you make in `mutate()` within the same call to the function:

```{r}
Data %>%
  select(statenme, year, cowintraongoing, 
         sideadeaths, sidebdeaths, wbpopest) %>%
  mutate(
    total_deaths = sideadeaths + sidebdeaths,
    deaths_pc = total_deaths / exp(wbpopest)
  )
```

See above, we can even do this all at once, by referring to columns that we have just created!

Or we can do it all in one equation, if we don’t need to save out a column for height in meters.

```{r}
Data %>%
  select(statenme, year, cowintraongoing, 
         sideadeaths, sidebdeaths, wbpopest) %>%
  mutate(
    deaths_pc = (sideadeaths + sidebdeaths) / exp(wbpopest)
  )
```


Note that as things are getting more complex, we just did one step at a time, and then went back to edit what we just did, making sure each step along the way worked before making it more complicated. This is a good recipe for success, and to cut down on frustration!

You could use any mathematical operators, here, including `sum(x)`, `y - mean(y)`, `log()`, `log2()`, `log10()`, `lead()`


### summarize() and group_by()

These can be used to collapse a dataframe to a single row, or a set of rows (if we use group_by()). For example, here's the mean number of civil wars in the data:

```{r}
Data %>%
  summarize(
    mean_wars = mean(cowintraongoing, na.rm=T)
  )
```

And here's that grouped by year:

```{r}
Data %>%
  group_by(year) %>%
  summarize(
    mean_wars = mean(cowintraongoing, na.rm=T)
  )
```

We could also filter this down so it's not just the total mean per year. Say we only want to look at major powers. And say we want to look at yearly deaths per capita:

```{r}
Data %>%
  filter(cowmaj==1) %>%
  mutate(
    deaths_pc = (sideadeaths + sidebdeaths) / exp(wbpopest)
  ) %>%
  group_by(year) %>%
  summarize(
    mean_deaths = mean(deaths_pc, na.rm=T)
  )
```

Finally, we also have data on democracy. What if we only look at those that scored a 0.5 or higher on the polyarchy index?

```{r}
Data %>%
  filter(cowmaj==1 & v2x_polyarchy > 0.5) %>%
  mutate(
    deaths_pc = (sideadeaths + sidebdeaths) / exp(wbpopest)
  ) %>%
  group_by(year) %>%
  summarize(
    mean_deaths = mean(deaths_pc, na.rm=T)
  )
```

Adding a column for count to go along with your summary can also be helpful, because it can help you see how many things were averaged (or whatever). You don’t want to draw conclusions from a very small number of samples!

Note: We can also calculate median (midpoint of the data), which tells us a little different information from mean (average)

```{r}
Data %>%
  filter(cowmaj==1, v2x_polyarchy > 0.5) %>%
  mutate(
    pop = exp(wbpopest),
    gdp = exp(wbgdp2011est),
    gdp_pc = gdp / pop
  ) %>%
  group_by(year) %>%
  summarize(
    gdp_pc = mean(gdp_pc),
    N = n()
  )
```

There a lot of different functions you can use:

- `mean()`: average
- `median()`: midpoint
- `sd()`: standard deviation
- `IQR()`: interquartile range
- `mad()`: median absolute deviation
- `min()`: minimum
- `max()`: maximum
- `quantile(x, 0.25)`: value in the data that is > 25% of the values and < 75% of the values
- `n()`: count
- `sum(!is.na(x))`: count all non-missing values (don’t count NAs)
- `n_distinct()`: count all distinct (unique) values


## From summarizing to plotting

Sometimes it will make sense to do a combination of `summarize()` and `group_by()` with your data before using `ggplot()` to plot relationships.

```{r}
Data %>%
  group_by(year) %>%
  summarize(
    conflict_rate = mean(cowintraonset)
  ) %>%
  ggplot() +
  aes(x = year, y = conflict_rate) +
  geom_col() +
  labs(
    x = NULL,
    y = "Rate of Initiation",
    title = "Conflict initiation over time, 1816-2007",
    caption = "Data: {peacesciencer}"
  )
```

